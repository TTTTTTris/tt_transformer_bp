{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dceaff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600,) (9600,)\n",
      "TT-core 0 in FFN-1 max elemental err: 0.02%\n",
      "TT-core 1 in FFN-1 max elemental err: 0.02%\n",
      "TT-core 2 in FFN-1 max elemental err: 0.02%\n",
      "TT-core 3 in FFN-1 max elemental err: 0.08%\n",
      "TT-core 4 in FFN-1 max elemental err: 0.04%\n",
      "TT-core 5 in FFN-1 max elemental err: 0.05%\n",
      "TT-core 0 in FFN-2 max elemental err: 0.03%\n",
      "TT-core 1 in FFN-2 max elemental err: 0.02%\n",
      "TT-core 2 in FFN-2 max elemental err: 0.17%\n",
      "TT-core 3 in FFN-2 max elemental err: 0.27%\n",
      "TT-core 4 in FFN-2 max elemental err: 0.04%\n",
      "TT-core 5 in FFN-2 max elemental err: 0.07%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "file1 = 'grad_cores_ff1.txt'\n",
    "file2 = 'grad_cores_ff2.txt'\n",
    "grad1 = np.loadtxt(file1)\n",
    "grad2 = np.loadtxt(file2)\n",
    "print(grad1.shape, grad2.shape)\n",
    "\n",
    "grad = {}\n",
    "grad1_ = {}\n",
    "grad2_ = {}\n",
    "WD = 10*16*10\n",
    "for k in range(12):\n",
    "    file = \"grad_cores_ffn/grad_ffn\" + str(k) + \".txt\";\n",
    "    grad[k] = np.loadtxt(file)\n",
    "    grad[k] = grad[k].flatten()\n",
    "    # print(grad[k].shape)\n",
    "    grad[k] = np.pad(grad[k].flatten(), (0, WD - len(grad[k].flatten())), 'constant')\n",
    "\n",
    "for i in range(6):\n",
    "    grad1_[i] = grad1[i*WD:(i+1)*WD]\n",
    "    grad2_[i] = grad2[i*WD:(i+1)*WD]\n",
    "\n",
    "for i in range(6):\n",
    "    index1 = np.argmax(np.abs(grad1_[i]-grad[i]))\n",
    "    # print(index1, grad1_[i][index1], grad[i][index1])\n",
    "    print('TT-core {:d}'.format(i), 'in FFN-1 max elemental err: {:.2%}'.format(np.abs((grad1_[i][index1]-grad[i][index1])/grad[i][index1])))\n",
    "for i in range(6):\n",
    "    index2 = np.argmax(np.abs(grad2_[i]-grad[i+6]))\n",
    "    # print(index2, grad2_[i][index2], grad[i+6][index2])\n",
    "    print('TT-core {:d}'.format(i), 'in FFN-2 max elemental err: {:.2%}'.format(np.abs((grad2_[i][index2]-grad[i+6][index2])/grad[i+6][index2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b8a4957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800,) (4800,) (4800,) (4800,)\n",
      "TT-core 0 in Q max elemental err: 0.07%\n",
      "TT-core 1 in Q max elemental err: 0.02%\n",
      "TT-core 2 in Q max elemental err: 0.03%\n",
      "TT-core 3 in Q max elemental err: 0.02%\n",
      "TT-core 4 in Q max elemental err: 0.01%\n",
      "TT-core 5 in Q max elemental err: 0.01%\n",
      "TT-core 0 in K max elemental err: 0.02%\n",
      "TT-core 1 in K max elemental err: 0.02%\n",
      "TT-core 2 in K max elemental err: 0.02%\n",
      "TT-core 3 in K max elemental err: 0.07%\n",
      "TT-core 4 in K max elemental err: 0.02%\n",
      "TT-core 5 in K max elemental err: 0.01%\n",
      "TT-core 0 in V max elemental err: 0.02%\n",
      "TT-core 1 in V max elemental err: 1.89%\n",
      "TT-core 2 in V max elemental err: 0.03%\n",
      "TT-core 3 in V max elemental err: 0.02%\n",
      "TT-core 4 in V max elemental err: 0.01%\n",
      "TT-core 5 in V max elemental err: 0.02%\n",
      "TT-core 0 in O max elemental err: 0.27%\n",
      "TT-core 1 in O max elemental err: 0.10%\n",
      "TT-core 2 in O max elemental err: 0.62%\n",
      "TT-core 3 in O max elemental err: 0.02%\n",
      "TT-core 4 in O max elemental err: 0.09%\n",
      "TT-core 5 in O max elemental err: 0.03%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "file1 = 'grad_cores_q.txt'\n",
    "file2 = 'grad_cores_k.txt'\n",
    "file3 = 'grad_cores_v.txt'\n",
    "file4 = 'grad_cores_fc.txt'\n",
    "grad1 = np.loadtxt(file1)\n",
    "grad2 = np.loadtxt(file2)\n",
    "grad3 = np.loadtxt(file3)\n",
    "grad4 = np.loadtxt(file4)\n",
    "print(grad1.shape, grad2.shape,grad3.shape,grad4.shape)\n",
    "\n",
    "grad = {}\n",
    "grad1_ = {}\n",
    "grad2_ = {}\n",
    "grad3_ = {}\n",
    "grad4_ = {}\n",
    "WD= 10*8*10\n",
    "for k in range(24):\n",
    "    file = \"grad_cores_attn/grad_attn\" + str(k) + \".txt\";\n",
    "    grad[k] = np.loadtxt(file)\n",
    "    grad[k] = grad[k].flatten()\n",
    "    # print(grad[k].shape)\n",
    "    grad[k] = np.pad(grad[k].flatten(), (0, WD - len(grad[k].flatten())), 'constant')\n",
    "\n",
    "for i in range(6):\n",
    "    grad1_[i] = grad1[i*WD:(i+1)*WD]\n",
    "    grad2_[i] = grad2[i*WD:(i+1)*WD]\n",
    "    grad3_[i] = grad3[i*WD:(i+1)*WD]\n",
    "    grad4_[i] = grad4[i*WD:(i+1)*WD]\n",
    "\n",
    "for i in range(6):\n",
    "    index1 = np.argmax(np.abs(grad1_[i]-grad[i]))\n",
    "    # print(index1, grad1_[i][index1], grad[i][index1])\n",
    "    print('TT-core {:d}'.format(i), 'in Q max elemental err: {:.2%}'.format(np.abs((grad1_[i][index1]-grad[i][index1])/grad[i][index1])))\n",
    "for i in range(6):\n",
    "    index2 = np.argmax(np.abs(grad2_[i]-grad[i+6]))\n",
    "    # print(index2, grad2_[i][index2], grad[i+6][index2])\n",
    "    print('TT-core {:d}'.format(i), 'in K max elemental err: {:.2%}'.format(np.abs((grad2_[i][index2]-grad[i+6][index2])/grad[i+6][index2])))\n",
    "for i in range(6):\n",
    "    index3 = np.argmax(np.abs(grad3_[i]-grad[i+12]))\n",
    "    # print(index3, grad3_[i][index3], grad[i+12][index3])\n",
    "    print('TT-core {:d}'.format(i), 'in V max elemental err: {:.2%}'.format(np.abs((grad3_[i][index3]-grad[i+12][index3])/grad[i+12][index3])))\n",
    "for i in range(6):\n",
    "    index4 = np.argmax(np.abs(grad4_[i]-grad[i+18]))\n",
    "    # print(index4, grad4_[i][index4], grad[i+6][index2])\n",
    "    print('TT-core {:d}'.format(i), 'in O max elemental err: {:.2%}'.format(np.abs((grad4_[i][index4]-grad[i+18][index4])/grad[i+18][index4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d065227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3593 -1.154943 -1.154948\n",
      "err: -0.0004%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "file1 = 'FFN_input.txt'\n",
    "file2 = 'input_o.txt'\n",
    "input1 = np.loadtxt(file1)\n",
    "input2 = np.loadtxt(file2)\n",
    "input1 = input1.flatten()\n",
    "index = np.argmax(input1-input2)\n",
    "print(index, input1[index], input2[index])\n",
    "print('err: {:.4%}'.format(np.max(input1[index]-input2[index])/input1[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8bd53fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 -0.054665 -0.054666\n",
      "err: -0.0018%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "file1 = 'g4g5g6dyx_ffn.txt'\n",
    "file2 = 'g4g5g6dyx.txt'\n",
    "input1 = np.loadtxt(file1)\n",
    "input2 = np.loadtxt(file2)\n",
    "input1 = input1.flatten()\n",
    "index = np.argmax(input1-input2)\n",
    "print(index, input1[index], input2[index])\n",
    "print('err: {:.4%}'.format(np.max(input1[index]-input2[index])/input1[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fde5f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 -0.003753 -0.003754\n",
      "err: -0.0266%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "file1 = 'grad_output1_ffn.txt'\n",
    "file2 = 'grad_output1.txt'\n",
    "input1 = np.loadtxt(file1)\n",
    "input2 = np.loadtxt(file2)\n",
    "input1 = input1.flatten()\n",
    "index = np.argmax(input1-input2)\n",
    "print(index, input1[index], input2[index])\n",
    "print('err: {:.4%}'.format(np.max(input1[index]-input2[index])/input1[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a3092ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.5422e-03,  1.1296e-02,  6.4169e-03,  ..., -1.4219e-02,\n",
      "          1.7477e-02, -2.2748e-03],\n",
      "        [-5.8085e-04,  2.3183e-04,  3.5711e-05,  ...,  1.0289e-04,\n",
      "         -1.3038e-04,  1.2927e-03],\n",
      "        [-1.7394e-04,  4.9918e-04,  3.9758e-04,  ..., -1.6527e-04,\n",
      "         -2.1644e-03,  8.9621e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "tensor([[ 4.3108e-03,  1.3112e-02,  4.7104e-03,  ..., -1.3977e-02,\n",
      "          1.8525e-02, -4.7682e-04],\n",
      "        [-8.7024e-04,  2.5602e-04,  2.4488e-04,  ...,  2.4681e-05,\n",
      "         -8.2065e-05,  1.3053e-03],\n",
      "        [-3.2105e-04,  5.0395e-04,  5.7853e-04,  ..., -2.3308e-04,\n",
      "         -2.1789e-03,  9.1371e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "tensor([[ 6.5710e-03,  1.1141e-02,  6.3990e-03,  ..., -1.4670e-02,\n",
      "          1.7613e-02, -2.8630e-03],\n",
      "        [-5.5400e-04,  2.8000e-04,  8.3000e-05,  ...,  1.5100e-04,\n",
      "         -1.2100e-04,  1.3400e-03],\n",
      "        [-1.5500e-04,  5.2100e-04,  3.7400e-04,  ..., -1.5600e-04,\n",
      "         -2.1130e-03,  1.0180e-03],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from layers import wrapped_linear_layers\n",
    "import torch.nn as nn\n",
    "from utils import config_class\n",
    "import torch \n",
    "import torch.optim as optim\n",
    "file = 'FFN_out_grad.txt'\n",
    "grad = np.loadtxt(file)\n",
    "pff = {}\n",
    "pff[0] = config_class(shape=[12,8,8,12,16,16],ranks=10,set_scale_factors=False)\n",
    "pff[1] = config_class(shape=[16,16,12,8,8,12],ranks=10,set_scale_factors=False)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "class Tensor_PFF(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.fc_1 = wrapped_linear_layers(768, 3072, tensorized=True,config=pff[0], bias=True)\n",
    "        self.fc_2 = wrapped_linear_layers(3072, 768, tensorized=True,config=pff[1], bias=True)\n",
    "\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm((768,), eps=1e-12)\n",
    "\n",
    "    def forward(self, x,config_forward=None):\n",
    "      \n",
    "        residual = x\n",
    "\n",
    "        x1 = self.fc_1(x,config_forward=config_forward)\n",
    "        x = self.act(x1)\n",
    "        x = self.fc_2(x,config_forward=config_forward)\n",
    "\n",
    "        x2 = x + residual\n",
    "\n",
    "        x = self.layer_norm(x2)\n",
    "        \n",
    "        return x, residual, x2\n",
    "\n",
    "pos_ffn = Tensor_PFF()\n",
    "pos_ffn.train()\n",
    "lr = 1e-3\n",
    "par = list(pos_ffn.parameters())\n",
    "optimizer = optim.Adam(par, betas=(0.9, 0.98), eps=1e-06, lr = lr)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "input = torch.from_numpy(input1.reshape(-1,768)).float().requires_grad_()\n",
    "enc_output2, enc_output1, ffn_out1 = pos_ffn(input)\n",
    "ffn_out1.retain_grad()\n",
    "enc_output1.retain_grad()\n",
    "enc_output2.retain_grad()\n",
    "enc_output2.backward(gradient = torch.from_numpy(grad))\n",
    "print(ffn_out1.grad)\n",
    "print(enc_output1.grad)\n",
    "print(enc_output2.grad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
